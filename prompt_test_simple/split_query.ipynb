{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41acde93-9ee5-4aa6-934e-0197f22536e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66312425-8a3c-4ad8-b891-491ef11c28f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953/1765561724.py:8: DeprecationWarning: This Wenxin LLM is deprecated. Please use `from langchain.chat_models import ChatWenxin` instead\n",
      "  llm = Wenxin(\n"
     ]
    }
   ],
   "source": [
    "from langchain_wenxin.llms import Wenxin\n",
    "from langchain.chat_models import ChatOpenAI, QianfanChatEndpoint\n",
    "from langchain.schema.messages import HumanMessage\n",
    "\n",
    "WENXIN_APP_Key = \"vtPwTlnPvgIdb4DRSuyNDuIN\"\n",
    "WENXIN_APP_SECRET = \"Sp8CCvNsQgUsRKlJozQwWVClRliZ2S8m\"\n",
    "\n",
    "llm = Wenxin(\n",
    "        temperature=0.0001,\n",
    "        model=\"ernie-bot-turbo\",\n",
    "        baidu_api_key = WENXIN_APP_Key,\n",
    "        baidu_secret_key = WENXIN_APP_SECRET,\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c1803b5-79d8-4db4-a2a7-29eb01d99e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_str = \"How do the models developed in this work compare to open-source chat models based on the benchmarks tested?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19a640d-4ad9-48c2-9ffb-cd9d20f24fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_gen_prompt_str = (\n",
    "    \"You are a helpful assistant that generates multiple search queries based on a \"\n",
    "    \"single input query. Generate {num_queries} search queries, one on each line, \"\n",
    "    \"related to the following input query:\\n\"\n",
    "    \"Query: {query}\\n\"\n",
    "    \"Queries:\\n\"\n",
    ")\n",
    "query_gen_prompt = PromptTemplate(query_gen_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cdd4d9-8c48-4767-9433-03bcff41dc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_queries(llm, query_str: str, num_queries: int = 4):\n",
    "    fmt_prompt = query_gen_prompt.format(\n",
    "        num_queries=num_queries - 1, query=query_str\n",
    "    )\n",
    "    response = llm(fmt_prompt)\n",
    "    queries = response.split(\"\\n\")\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea10f589-c8ee-4849-b286-a59c21cbe8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries = generate_queries(llm, query_str, num_queries=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3be4f2c-be5d-41ad-b1fd-594d1da5649b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Query: How do the models developed in this work compare to open-source chat models based on the benchmarks tested?', 'Query 1: How does the model developed in this work perform compared to the open-source chat models tested in benchmarks?', 'Query 2: What are the key differences between the model developed in this work and the open-source chat models tested in benchmarks?', 'Query 3: How does the model developed in this work compare to other open-source chat models based on user satisfaction and reliability?']\n"
     ]
    }
   ],
   "source": [
    "print(queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
